{"cells": [{"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "code", "source": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline", "execution_count": 11, "outputs": []}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "### About dataset"}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "This dataset is about\n\n| Field          | Description                                                                           |\n|----------------|---------------------------------------------------------------------------------------|\n| "}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "### Load Data From CSV File  "}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "code", "source": "#df = pd.read_csv('loan_train.csv')\n#df.head()", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#df.shape", "execution_count": 13, "outputs": []}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "# Data visualization and pre-processing\n\n"}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "Let\u2019s see how many of each class is in our data set "}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "code", "source": "#df['loan_status'].value_counts()", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Lets plot some columns to underestand data better:"}, {"metadata": {}, "cell_type": "code", "source": "# notice: installing seaborn might takes a few minutes\n#!conda install -c anaconda seaborn -y", "execution_count": 15, "outputs": []}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "\n"}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "\n"}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "## Normalize Data "}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "Data Standardization give data zero mean and unit variance (technically should be done after train test split )"}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "code", "source": "X = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]", "execution_count": 16, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'X' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-16-d237e5027ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]}]}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "# Classification "}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\nYou should use the following algorithm:\n- K Nearest Neighbor(KNN)\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression\n\n\n\n__ Notice:__ \n- You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n- You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n- You should include the code of the algorithm in the following cells."}, {"metadata": {}, "cell_type": "markdown", "source": "# K Nearest Neighbor(KNN)\nNotice: You should find the best k to build the model with the best accuracy.  \n**warning:** You should not use the __loan_test.csv__ for finding the best k, however, you can split your train_loan.csv into train and test to find the best __k__."}, {"metadata": {}, "cell_type": "code", "source": "# We split the X into train and test to find the best k\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Modeling\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 3\n#Train Model and Predict  \nkNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\nkNN_model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# just for sanity chaeck\nyhat = kNN_model.predict(X_test)\nyhat[0:5]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Best k\nKs=15\nmean_acc=np.zeros((Ks-1))\nstd_acc=np.zeros((Ks-1))\nConfustionMx=[];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    kNN_model = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)\n    yhat = kNN_model.predict(X_test)\n    \n    \n    mean_acc[n-1]=np.mean(yhat==y_test);\n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\nmean_acc", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Building the model again, using k=7\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 7\n#Train Model and Predict  \nkNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\nkNN_model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Decision Tree"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.tree import DecisionTreeClassifier\nDT_model = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nDT_model.fit(X_train,y_train)\nDT_model\n#Grud ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "yhat = DT_model.predict(X_test)\nyhat", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Support Vector Machine"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import svm\nSVM_model = svm.SVC()\nSVM_model.fit(X_train, y_train) ", "execution_count": 17, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'X_train' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-17-8b592a344fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSVM_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mSVM_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}]}, {"metadata": {}, "cell_type": "code", "source": "yhat = SVM_model.predict(X_test)\nyhat", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Logistic Regression"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.linear_model import LogisticRegression\nLR_model = LogisticRegression(C=0.01).fit(X_train,y_train)\nLR_model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "yhat = LR_model.predict(X_test)\nyhat", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Model Evaluation using Test set"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "First, download and load the test set:"}, {"metadata": {}, "cell_type": "code", "source": "load data set", "execution_count": null, "outputs": []}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "markdown", "source": "### Load Test set for evaluation "}, {"metadata": {"button": false, "new_sheet": false, "run_control": {"read_only": false}}, "cell_type": "code", "source": "test_df = pd.read_csv('loan_test.csv')\ntest_df.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "test_y = test_df['loan_status'].values\ntest_y[0:5]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "knn_yhat = kNN_model.predict(test_X)\nprint(\"KNN Jaccard index: %.2f\" % jaccard_similarity_score(test_y, knn_yhat))\nprint(\"KNN F1-score: %.2f\" % f1_score(test_y, knn_yhat, average='weighted') )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "DT_yhat = DT_model.predict(test_X)\nprint(\"DT Jaccard index: %.2f\" % jaccard_similarity_score(test_y, DT_yhat))\nprint(\"DT F1-score: %.2f\" % f1_score(test_y, DT_yhat, average='weighted') )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "SVM_yhat = SVM_model.predict(test_X)\nprint(\"SVM Jaccard index: %.2f\" % jaccard_similarity_score(test_y, SVM_yhat))\nprint(\"SVM F1-score: %.2f\" % f1_score(test_y, SVM_yhat, average='weighted') )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "LR_yhat = LR_model.predict(test_X)\nLR_yhat_prob = LR_model.predict_proba(test_X)\nprint(\"LR Jaccard index: %.2f\" % jaccard_similarity_score(test_y, LR_yhat))\nprint(\"LR F1-score: %.2f\" % f1_score(test_y, LR_yhat, average='weighted') )\nprint(\"LR LogLoss: %.2f\" % log_loss(test_y, LR_yhat_prob))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Report\nYou should be able to report the accuracy of the built model using different evaluation metrics:"}, {"metadata": {}, "cell_type": "markdown", "source": "| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                | 0.67    | 0.63     | NA      |\n| Decision Tree      | 0.72    | 0.74     | NA      |\n| SVM                | 0.80    | 0.76     | NA      |\n| LogisticRegression | 0.74    | 0.66     | 0.57    |"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}